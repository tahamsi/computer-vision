{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tahamsi/computer-vision/blob/main/week-9/Instance_segmentation_with_yolo11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/tahamsi/computer-vision)"
      ],
      "metadata": {
        "id": "EiDQllW5tOAD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe9vkEvFABbN"
      },
      "source": [
        "##YOLO\n",
        "YOLO (You Only Look Once) is a popular deep learning model used for real-time object detection. It was introduced by Joseph Redmon and is known for its ability to detect multiple objects in an image or video frame with high speed and accuracy. YOLO stands out due to its innovative approach of treating object detection as a single regression problem, enabling it to predict bounding boxes and class probabilities directly from full images in one evaluation.\n",
        "\n",
        "###Key Features\n",
        "\n",
        "* Single-Pass Detection: Unlike traditional object detection methods that use a multi-stage process (e.g., region proposal and classification), YOLO processes an image in a single neural network pass, making it extremely fast and suitable for real-time applications.\n",
        "* Grid-Based Prediction: YOLO divides the input image into a grid and assigns each grid cell the responsibility of predicting bounding boxes and their associated class probabilities if the center of an object falls within that cell.\n",
        "* End-to-End Learning: The model is trained end-to-end, optimizing for both object localization and classification simultaneously.\n",
        "* Speed and Efficiency: YOLO is capable of processing images at high frame rates, making it suitable for applications that require real-time performance, such as video surveillance, autonomous vehicles, and interactive systems.\n",
        "##YOLO11\n",
        "[Ultralytics YOLO11](https://github.com/ultralytics/ultralytics) is a state-of-the-art model that builds on the success of previous YOLO versions, incorporating new features and enhancements to further improve performance and flexibility. YOLO11 is designed to be fast, accurate, and user-friendly, making it an ideal choice for a variety of tasks, including object detection, tracking, instance segmentation, image classification, and pose estimation.\n",
        "YOLO11 builds on the advancements introduced in YOLOv9 and YOLOv10 earlier this year, incorporating improved architectural designs, enhanced feature extraction techniques, and optimized training methods.\n",
        "\n",
        "YOLO11m achieves a higher mean mAP score on the COCO dataset while using 22% fewer parameters than YOLOv8m, making it computationally lighter without sacrificing performance.\n",
        "\n",
        "YOLOv11 is available in 5 different sizes, ranging from `2.6M` to `56.9M` parameters, and capable of achieving from `39.5` to `54.7` mAP on the COCO dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyRdDYkqAKN4"
      },
      "source": [
        "### Before you start\n",
        "\n",
        "Let's ensure we have `GPU` access by using the `nvidia-smi` command to check. If there are any issues, go to `Edit -> Notebook settings -> Hardware accelerator`, set it to GPU, and then click `Save`. The codes here are extended from [Ultralytics](https://github.com/ultralytics/ultralytics) and [Roboflow](https://github.com/roboflow/notebooks)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8cDtxLIBHgQ"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjpPg4mGKc1v"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "HOME = os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C3EO_2zNChu"
      },
      "source": [
        "## Install YOLO11 via Ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdSMcABDNKW-"
      },
      "outputs": [],
      "source": [
        "%pip install ultralytics supervision roboflow\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5RGYA6sPgEd"
      },
      "source": [
        "## Inference with model pre-trained on COCO dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download sample data"
      ],
      "metadata": {
        "id": "msX24UQxqj-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p {HOME}/data\n",
        "!wget https://raw.githubusercontent.com/tahamsi/computer-vision/refs/heads/main/images/peel.jpg -P {HOME}/data\n",
        "!wget https://raw.githubusercontent.com/tahamsi/computer-vision/refs/heads/main/images/London_bridge.jpg -P {HOME}/data"
      ],
      "metadata": {
        "id": "tXjwCkwJqnbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT1qD4toTTw0"
      },
      "source": [
        "### CLI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDbMt_M6PiXb"
      },
      "outputs": [],
      "source": [
        "!yolo task=segment mode=predict model=yolo11l-seg.pt conf=0.25 source='data/London_bridge.jpg' save=True"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Result annotated image are saved in `{HOME}/runs/segment/predict/`."
      ],
      "metadata": {
        "id": "MCnCBKqzlo1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "IPyImage(filename=f'/content/runs/segment/predict/London_bridge.jpg', width=600)"
      ],
      "metadata": {
        "id": "eIskqLWxEfPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFMBYQtMVL-B"
      },
      "source": [
        "### SDK\n",
        "\n",
        "**NOTE:** YOLO's Python interface allows for seamless integration into your Python projects, making it easy to load, run, and process the model's output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rx9NWF-sVN6Y"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "\n",
        "model = YOLO('yolo11l-seg.pt')\n",
        "image = Image.open('data/London_bridge.jpg')\n",
        "result = model.predict(image, conf=0.25)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** The obtained `result` object stores information about the location, classes, and confidence levels of the detected objects."
      ],
      "metadata": {
        "id": "z1XBAm7toMd7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAi4PvrItTCf"
      },
      "outputs": [],
      "source": [
        "result.boxes.xyxy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqT2M01K1LUb"
      },
      "outputs": [],
      "source": [
        "result.boxes.conf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKIwJ5yw1PMb"
      },
      "outputs": [],
      "source": [
        "result.boxes.cls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.masks.data"
      ],
      "metadata": {
        "id": "pDl8Pm6iXkoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** YOLO11 can be easily integrated with `supervision` using the familiar `from_ultralytics` connector.\n",
        "\n",
        "NOTE: [Roboflow Supervision](https://github.com/roboflow/supervision) refers to a set of tools and features provided by Roboflow, a platform designed to simplify and enhance the development of computer vision models. Roboflow offers a comprehensive suite for data annotation, preprocessing, model training, and deployment, aimed at improving the workflow and performance of machine learning projects."
      ],
      "metadata": {
        "id": "4PZPP_Jnn4IO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "\n",
        "detections = sv.Detections.from_ultralytics(result)"
      ],
      "metadata": {
        "id": "E4EUcnOMnw_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_annotator = sv.MaskAnnotator()\n",
        "label_annotator = sv.LabelAnnotator(text_color=sv.Color.BLACK, text_position=sv.Position.CENTER)\n",
        "\n",
        "annotated_image = image.copy()\n",
        "annotated_image = mask_annotator.annotate(annotated_image, detections=detections)\n",
        "annotated_image = label_annotator.annotate(annotated_image, detections=detections)\n",
        "\n",
        "sv.plot_image(annotated_image, size=(10, 10))"
      ],
      "metadata": {
        "id": "yTjp0rx6EVl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune YOLO11"
      ],
      "metadata": {
        "id": "oSI-qYxsG6Wl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### API keys\n",
        "\n",
        "To fine-tune YOLO11, you’ll need to provide your Roboflow API key. Follow these steps:\n",
        "\n",
        "Visit your [`Roboflow Settings`](https://app.roboflow.com/settings/api) page, and click `Copy` to copy your private API key to the clipboard."
      ],
      "metadata": {
        "id": "eVUOzebCoaRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When training YOLOv11, ensure your data is stored in the `datasets` folder. To modify the default location for your fine-tuning data, adjust the path in Ultralytics’ `settings.json`. In this tutorial, we’ll use a sample [dataset](https://universe.roboflow.com/detect-microplastic/new-project-2-bchc8/dataset/2#) from [Roboflow Universe](https://universe.roboflow.com/), specifically the microplastic dataset. When downloading, select the `YOLOv11` export format."
      ],
      "metadata": {
        "id": "YGOP0bCgH4cb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSd93ZJzZZKt"
      },
      "outputs": [],
      "source": [
        "!mkdir {HOME}/datasets\n",
        "%cd {HOME}/datasets\n",
        "\n",
        "from google.colab import userdata\n",
        "from roboflow import Roboflow\n",
        "\n",
        "rf = Roboflow(api_key=\"\") #copy and paste your api key from roboflow\n",
        "project = rf.workspace(\"detect-microplastic\").project(\"new-project-2-bchc8\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov11\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUjFBKKqXa-u"
      },
      "source": [
        "## Custom Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2YkphuiaE7_"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "\n",
        "!yolo task=segment mode=train model=yolo11s-seg.pt data={dataset.location}/data.yaml epochs=10 imgsz=640 plots=True"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** The results of the completed training are saved in `{HOME}/runs/detect/train/`. Let's examine them."
      ],
      "metadata": {
        "id": "3mkT-rUhqQLp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MScstfHhArr"
      },
      "outputs": [],
      "source": [
        "!ls {HOME}/runs/segment/train/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_J35i8Ofhjxa"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "IPyImage(filename=f'{HOME}/runs/segment/train/confusion_matrix.png', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-urTWUkhRmn"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "IPyImage(filename=f'{HOME}/runs/segment/train/results.png', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HI4nADCCj3F5"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "IPyImage(filename=f'{HOME}/runs/segment/train/val_batch0_pred.jpg', width=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ODk1VTlevxn"
      },
      "source": [
        "## Validate fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpyuwrNlXc1P"
      },
      "outputs": [],
      "source": [
        "!yolo task=segment mode=val model={HOME}/runs/segment/train/weights/best.pt data={dataset.location}/data.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4eASbcWkQBq"
      },
      "source": [
        "## Inference with custom model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wjc1ctZykYuf"
      },
      "outputs": [],
      "source": [
        "!yolo task=segment mode=predict model={HOME}/runs/segment/train/weights/best.pt conf=0.25 source={dataset.location}/test/images save=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEYIo95n-I0S"
      },
      "source": [
        "Check a few results."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "from IPython.display import Image as IPyImage, display\n",
        "\n",
        "latest_folder = max(glob.glob(f'{HOME}/runs/segment/predict*/'), key=os.path.getmtime)\n",
        "for img in glob.glob(f'{latest_folder}/*.jpg')[:3]:\n",
        "    display(IPyImage(filename=img, width=600))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "1nOnTQynZfeA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}